{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to reformat methane data files for TWO 2-level Sankeys\n",
    "#Output: tsv file\n",
    "\n",
    "#Created:           17.11.2018   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "#import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define sources and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\"Estuaries\", \"Lakes\", \"Rivers\"]\n",
    "\n",
    "target2_lats = ['High lat', 'Mid lat', 'Tropics']\n",
    "target2_regions = ['N America', 'S America', 'Africa', 'Asia', 'Europe', 'Oceania']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 6, saw 76\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c28594bbd209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df1 = pd.read_csv(fname1, sep=\"\\t\", skiprows=[0], header = None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nangini/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nangini/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nangini/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nangini/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 6, saw 76\n"
     ]
    }
   ],
   "source": [
    "fname = '/home/nangini/Documents/PROJECTS/TRANSPORTCAN/DATA/MOTORVEHICLE/2310006601-eng.csv'\n",
    "\n",
    "#df1 = pd.read_csv(fname1, sep=\"\\t\", skiprows=[0], header = None)\n",
    "df = pd.read_csv(fname)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>N America</th>\n",
       "      <th>S America</th>\n",
       "      <th>Africa</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Oceania</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estuaries</td>\n",
       "      <td>40.262894</td>\n",
       "      <td>12.465882</td>\n",
       "      <td>14.700063</td>\n",
       "      <td>52.301511</td>\n",
       "      <td>23.396577</td>\n",
       "      <td>8.894408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lakes</td>\n",
       "      <td>192.459815</td>\n",
       "      <td>41.728928</td>\n",
       "      <td>37.139858</td>\n",
       "      <td>161.316415</td>\n",
       "      <td>55.004972</td>\n",
       "      <td>2.661126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rivers</td>\n",
       "      <td>46.141748</td>\n",
       "      <td>270.921282</td>\n",
       "      <td>137.567182</td>\n",
       "      <td>166.421382</td>\n",
       "      <td>20.345204</td>\n",
       "      <td>8.489645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Source   N America   S America      Africa        Asia     Europe  \\\n",
       "0  Estuaries   40.262894   12.465882   14.700063   52.301511  23.396577   \n",
       "1      Lakes  192.459815   41.728928   37.139858  161.316415  55.004972   \n",
       "2     Rivers   46.141748  270.921282  137.567182  166.421382  20.345204   \n",
       "\n",
       "    Oceania  \n",
       "0  8.894408  \n",
       "1  2.661126  \n",
       "2  8.489645  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname2 = '/home/nangini/Documents/PROJECTS/CCASCADES/DATA/LOAC_budget_TgCyr181113_sankey2.tsv'\n",
    "\n",
    "df2 = pd.read_csv(fname2, sep=\"\\t\")\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estuaries', 'Lakes', 'Rivers', 'High lat', 'Mid lat', 'Tropics']\n"
     ]
    }
   ],
   "source": [
    "#Sankey1\n",
    "nodes1 = sources + target2_lats\n",
    "print nodes1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estuaries', 'Lakes', 'Rivers', 'N America', 'S America', 'Africa', 'Asia', 'Europe', 'Oceania']\n"
     ]
    }
   ],
   "source": [
    "#Sakney2\n",
    "nodes2 = sources + target2_regions\n",
    "print nodes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Estuaries', 'Lakes', 'Rivers']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write json file for 2-level Sankey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_2level_sankey(df, nodes, targets, file):\n",
    "    \"\"\" Format dataframe data into the json format needed for a Sankey diagram. Output to file.\"\"\"\n",
    "    \n",
    "    file.write('{\\n')\n",
    "    file.write('\"nodes\": [\\n')\n",
    "    for node in nodes:\n",
    "        file.write('{\"name\": \"%s\"},\\n' %(node))\n",
    "    # remove last comma\n",
    "    file.seek(-2, os.SEEK_END)\n",
    "    file.truncate()\n",
    "    file.write('\\n],\\n')\n",
    "\n",
    "    file.write('\"links\": [\\n')\n",
    "\n",
    "    #source-target pairs for sources -> regions\n",
    "    for source in sources:\n",
    "        print source\n",
    "        for t1 in targets:\n",
    "            #print region\n",
    "            value = df.loc[df['Source'] == source, t1].values[0]\n",
    "            #print value\n",
    "            file.write('{\"source\": \"%s\", \"target\": \"%s\", \"value\": \"%.2f\"},\\n' %(source, t1, float(value)))                \n",
    "\n",
    "    # remove last comma\n",
    "    file.seek(-2, os.SEEK_END)\n",
    "    file.truncate()\n",
    "    file.write('\\n]\\n')\n",
    "    file.write('}\\n')\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estuaries\n",
      "Lakes\n",
      "Rivers\n"
     ]
    }
   ],
   "source": [
    "#Sankey1\n",
    "\n",
    "dir = '/home/nangini/PROJECTS/C-CASCADES/data/'\n",
    "file = open(dir + 'LOAC_budget_TgCyr181113_sankey1.json', 'w')\n",
    "\n",
    "make_2level_sankey(df1, nodes1, target2_lats, file)\n",
    "\n",
    "# nodes = nodes1\n",
    "# targets = target2_lats\n",
    "# df = df1\n",
    "\n",
    "# file.write('{\\n')\n",
    "# file.write('\"nodes\": [\\n')\n",
    "# for node in nodes:\n",
    "#     file.write('{\"name\": \"%s\"},\\n' %(node))\n",
    "# # remove last comma\n",
    "# file.seek(-2, os.SEEK_END)\n",
    "# file.truncate()\n",
    "# file.write('\\n],\\n')\n",
    "\n",
    "# file.write('\"links\": [\\n')\n",
    "\n",
    "# #source-target pairs for sources -> regions\n",
    "# for source in sources:\n",
    "#     print source\n",
    "#     for t1 in targets:\n",
    "#         #print region\n",
    "#         value = df.loc[df['Source'] == source, t1].values[0]\n",
    "#         #print value\n",
    "#         file.write('{\"source\": \"%s\", \"target\": \"%s\", \"value\": \"%.2f\"},\\n' %(source, t1, float(value)))                \n",
    "\n",
    "# # remove last comma\n",
    "# file.seek(-2, os.SEEK_END)\n",
    "# file.truncate()\n",
    "# file.write('\\n]\\n')\n",
    "# file.write('}\\n')\n",
    "\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estuaries\n",
      "Lakes\n",
      "Rivers\n"
     ]
    }
   ],
   "source": [
    "#Sankey2\n",
    "\n",
    "dir = '/home/nangini/PROJECTS/C-CASCADES/data/'\n",
    "file = open(dir + 'LOAC_budget_TgCyr181113_sankey2.json', 'w')\n",
    "\n",
    "make_2level_sankey(df2, nodes2, target2_regions, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Estuaries',\n",
       " 'Lakes',\n",
       " 'Rivers',\n",
       " 'N America',\n",
       " 'S America',\n",
       " 'Africa',\n",
       " 'Asia',\n",
       " 'Europe',\n",
       " 'Oceania']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N America', 'S America', 'Africa', 'Asia', 'Europe', 'Oceania']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target2_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
